HTRPOconfig = {
    'cg_damping': 1e-3,
    'GAE_lambda': 0.,
    'reward_decay': 0.95,
    'max_kl_divergence': 2e-5,
    'goal_space': None,
    'per_decision': True,
    'weighted_is': True,
    'using_active_goals': True,
    'hidden_layers': [64, 64],
    'hidden_layers_v': [64, 64],
    'max_grad_norm': None,
    'value_lr': 5e-4,
    'train_v_iters': 10,
    'lr_pi': 1e-3,
    'sampled_goal_num': None,
    'steps_per_iter': 256,
    'value_func_type': 'FC',
    'entropy_weight': 0,
}
HTRPOconfig['memory_size'] = HTRPOconfig['steps_per_iter']
